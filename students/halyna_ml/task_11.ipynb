{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семантика\n",
    "\n",
    "## Завдання\n",
    "\n",
    "Одне із змагань на SemEval-2015 було пов'язане з пошуком перефразувань та схожих за змістом твітів - [Paraphrase and Semantic Similarity in Twitter](http://alt.qcri.org/semeval2015/task1/). Ваше завдання цього тижня - побудувати модель, яка буде визначати перефразування та/або семантичну подібність краще, ніж бейзлайн у цьому змаганні.\n",
    "\n",
    "Побудуйте одне із запропонованих рішень для цієї задачі (на вибір):\n",
    "\n",
    "1. Побудуйте класифікатор на лінгвістичних ознаках (сутності, енграми слів чи символів, корені слів, редакторська відстань, синтаксична та семантична подібність тощо). **Обов'язкова умова** - використання семантичних ознак. Наприклад:\n",
    "   - перетин слів та їх синонімів, гіпонімів, пов'язаних за темою слів тощо\n",
    "   - середня близькість речень по онтології\n",
    "   - редакторська відстань по AMR-графу\n",
    "   - збіги по семантичних ролях\n",
    "\n",
    "NE overlap( people, dates, currency), unigram/bigram overlap, stem overlap\n",
    "сер близбкість речень по онтології (буз служ чатсин мови)\n",
    "t1 \n",
    "t2\n",
    "найкоротшиа відстань \n",
    "\n",
    "2. Побудуйте класифікатор на основі ваших улюблений векторних представлень слів. Поекспериментуйте з різними способами агрегації, відбору та зважування векторів. **Обов'язкова умова** - використання семантично збагачених векторів (як основне рішення чи для порівняння). Можна взяти готові вектори (наприклад, [ConceptNet Numberbatch](https://github.com/commonsense/conceptnet-numberbatch)) або самостійно виконати [ретрофіттинг](https://github.com/mfaruqui/retrofitting/blob/master/retrofit.py) на будь-яких стандартних векторах.\n",
    "\n",
    "Більше натхнення щодо ознак та варіантів побудови рішення можна черпати зі [звіту про змагання](https://www.aclweb.org/anthology/S15-2001).\n",
    "\n",
    "### Дані\n",
    "\n",
    "Використайте дані та метрики з репозиторію змагання SemEval-2015 (архів опубліковано через Слек). Вся інформація щодо формату корпусу та метрик міститься в Readme.md.\n",
    "\n",
    "Запустити метрику можна таким способом:\n",
    "```\n",
    "$ python scripts/pit2015_eval_single.py data/test.label systemoutputs/PIT2015_BASELINE_02_LG.output\n",
    "838     BASELINE        02_LG           F: 0.589        Prec: 0.679     Rec: 0.520              P-corr: 0.511   F1: 0.601       Prec: 0.674     Rec: 0.543\n",
    "```\n",
    "\n",
    "**Важливо**: не заточуйтесь на test-дані. У корпусі є окремо виділений dev-сет, на якому можна порівнювати ваші рішення.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import porter\n",
    "\n",
    "from _pickle import load\n",
    "from _pickle import dump\n",
    "\n",
    "from collections import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# import nltk\n",
    "# from langdetect import detect \n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.metrics import precision_recall_fscore_support\n",
    "# from sklearn.metrics import classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from train/test data files and create features\n",
    "def readInData(filename):\n",
    "\n",
    "    data = []\n",
    "    trends = set([])\n",
    "    \n",
    "    (trendid, trendname, origsent, candsent, judge, origsenttag, candsenttag) = (None, None, None, None, None, None, None)\n",
    "    \n",
    "    check = []\n",
    "    for i, line in enumerate(open(filename)):\n",
    "        line = line.strip()\n",
    "        #read in training or dev data with labels\n",
    "        if len(line.split('\\t')) == 7:\n",
    "            (trendid, trendname, origsent, candsent, judge, origsenttag, candsenttag) = line.split('\\t')\n",
    "            check.append((i, 7))\n",
    "        #read in test data without labels\n",
    "        elif len(line.split('\\t')) == 6:\n",
    "            (trendid, trendname, origsent, candsent, origsenttag, candsenttag) = line.split('\\t')\n",
    "            check.append((i, 6))\n",
    "        else:\n",
    "            check.append((i, 0))\n",
    "            continue\n",
    "        \n",
    "        #if origsent == candsent:\n",
    "        #    continue\n",
    "        \n",
    "        trends.add(trendid)\n",
    "        #features = paraphrase_Das_features(origsent, candsent, trendname)\n",
    "        \n",
    "        if judge == None:\n",
    "            data.append((judge, origsent, candsent,  origsenttag, candsenttag, trendid))\n",
    "            continue\n",
    "\n",
    "        # ignoring the training/test data that has middle label \n",
    "        if judge[0] == '(':  # labelled by Amazon Mechanical Turk in format like \"(2,3)\"\n",
    "            nYes = eval(judge)[0]            \n",
    "            if nYes >= 3:\n",
    "                amt_label = True\n",
    "                data.append((amt_label, origsent, candsent,  origsenttag, candsenttag, trendid))\n",
    "            elif nYes <= 1:\n",
    "                amt_label = False\n",
    "                data.append((amt_label, origsent, candsent,  origsenttag, candsenttag, trendid))   \n",
    "        elif judge[0].isdigit():   # labelled by expert in format like \"2\"\n",
    "            nYes = int(judge[0])\n",
    "            if nYes >= 4:\n",
    "                expert_label = True\n",
    "                data.append((expert_label, origsent, candsent,  origsenttag, candsenttag, trendid))\n",
    "            elif nYes <= 2:\n",
    "                expert_label = False\n",
    "                data.append((expert_label, origsent, candsent,  origsenttag, candsenttag, trendid))     \n",
    "            else:\n",
    "            \texpert_label = None\n",
    "            \tdata.append((expert_label, origsent, candsent,  origsenttag, candsenttag, trendid))        \n",
    "                \n",
    "    return pd.DataFrame(data, columns =['label', 'origsent', 'candsent',  'origsenttag', 'candsenttag', 'trendid']),\\\n",
    "            trends, check\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfilename = \"data/train.data\"\n",
    "testfilename  = \"data/test.data\"\n",
    "# modelfile = 'scripts//baseline_logisticregression.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfull, traintrends  = readInData(trainfilename)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfull, testtrends, check  = readInData(testfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>origsent</th>\n",
       "      <th>candsent</th>\n",
       "      <th>origsenttag</th>\n",
       "      <th>candsenttag</th>\n",
       "      <th>trendid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>All the home alones watching 8 mile</td>\n",
       "      <td>8 mile is on thats my movie</td>\n",
       "      <td>All/O/DT/B-NP/O the/O/DT/I-NP/O home/O/NN/I-NP/O alones/O/VBZ/B-VP/O watching/O/VBG/I-VP/B-EVENT 8/O/CD/B-NP/O mile/O/NN/I-NP/O</td>\n",
       "      <td>8/O/NN/B-NP/O mile/O/NN/I-NP/O is/O/VBZ/B-VP/O on/O/IN/B-PP/O thats/O/NNS/B-NP/O my/O/PRP$/B-NP/O movie/O/NN/I-NP/B-EVENT</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>All the home alones watching 8 mile</td>\n",
       "      <td>The last rap battle in 8 Mile nevr gets old ahah</td>\n",
       "      <td>All/O/DT/B-NP/O the/O/DT/I-NP/O home/O/NN/I-NP/O alones/O/VBZ/B-VP/O watching/O/VBG/I-VP/B-EVENT 8/O/CD/B-NP/O mile/O/NN/I-NP/O</td>\n",
       "      <td>The/O/DT/B-NP/O last/O/JJ/I-NP/O rap/O/NN/I-NP/B-EVENT battle/O/NN/I-NP/B-EVENT in/O/IN/B-PP/O 8/O/CD/B-NP/O Mile/O/NNP/I-NP/O nevr/O/NN/I-NP/O gets/O/VBZ/B-VP/O old/O/JJ/B-NP/O ahah/O/JJ/I-NP/O</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>All the home alones watching 8 mile</td>\n",
       "      <td>The rap battle at the end of 8 mile gets me so hype</td>\n",
       "      <td>All/O/DT/B-NP/O the/O/DT/I-NP/O home/O/NN/I-NP/O alones/O/VBZ/B-VP/O watching/O/VBG/I-VP/B-EVENT 8/O/CD/B-NP/O mile/O/NN/I-NP/O</td>\n",
       "      <td>The/O/DT/B-NP/O rap/O/NN/I-NP/O battle/O/NN/I-NP/B-EVENT at/O/IN/B-PP/O the/O/DT/B-NP/O end/O/NN/I-NP/O of/O/IN/B-PP/O 8/O/CD/B-NP/O mile/O/NN/I-NP/O gets/O/VBZ/B-VP/O me/O/PRP/B-NP/O so/O/RB/B-ADVP/O hype/O/JJ/I-ADVP/O</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>The Ending to 8 Mile is my fav part of the whole movie</td>\n",
       "      <td>Rabbit on 8 mile out of place but determined to make it</td>\n",
       "      <td>The/O/DT/B-NP/O Ending/O/VBG/I-NP/B-EVENT to/O/TO/I-NP/O 8/O/CD/I-NP/O Mile/O/NNP/I-NP/O is/O/VBZ/B-VP/O my/O/PRP$/B-NP/O fav/O/JJ/I-NP/O part/O/NN/I-NP/O of/O/IN/B-PP/O the/O/DT/B-NP/O whole/O/JJ/I-NP/O movie/O/NN/I-NP/B-EVENT</td>\n",
       "      <td>Rabbit/O/NNP/B-NP/O on/O/IN/B-PP/O 8/O/CD/B-NP/O mile/O/NN/I-NP/O out/O/IN/B-PP/O of/O/IN/B-PP/O place/O/NN/B-NP/O but/O/CC/O/O determined/O/VBD/B-VP/B-EVENT to/O/TO/I-VP/O make/O/VB/I-VP/O it/O/PRP/B-NP/O</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>The Ending to 8 Mile is my fav part of the whole movie</td>\n",
       "      <td>See 8 Mile is always on but it s the tv version so it s gay</td>\n",
       "      <td>The/O/DT/B-NP/O Ending/O/VBG/I-NP/B-EVENT to/O/TO/I-NP/O 8/O/CD/I-NP/O Mile/O/NNP/I-NP/O is/O/VBZ/B-VP/O my/O/PRP$/B-NP/O fav/O/JJ/I-NP/O part/O/NN/I-NP/O of/O/IN/B-PP/O the/O/DT/B-NP/O whole/O/JJ/I-NP/O movie/O/NN/I-NP/B-EVENT</td>\n",
       "      <td>See/O/VB/B-VP/O 8/O/CD/B-NP/O Mile/O/NNP/I-NP/O is/O/VBZ/B-VP/O always/O/RB/B-ADVP/O on/O/IN/B-PP/O but/O/CC/O/O it/O/PRP/B-NP/O s/O/VBZ/B-VP/O the/O/DT/B-NP/O tv/O/NN/I-NP/O version/O/NN/I-NP/B-EVENT so/O/IN/B-SBAR/O it/O/PRP/B-NP/O s/O/RB/B-ADJP/O gay/O/JJ/I-ADJP/O</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                origsent  \\\n",
       "0   None                     All the home alones watching 8 mile   \n",
       "1  False                     All the home alones watching 8 mile   \n",
       "2  False                     All the home alones watching 8 mile   \n",
       "3  False  The Ending to 8 Mile is my fav part of the whole movie   \n",
       "4  False  The Ending to 8 Mile is my fav part of the whole movie   \n",
       "\n",
       "                                                      candsent  \\\n",
       "0                                  8 mile is on thats my movie   \n",
       "1             The last rap battle in 8 Mile nevr gets old ahah   \n",
       "2          The rap battle at the end of 8 mile gets me so hype   \n",
       "3      Rabbit on 8 mile out of place but determined to make it   \n",
       "4  See 8 Mile is always on but it s the tv version so it s gay   \n",
       "\n",
       "                                                                                                                                                                                                                           origsenttag  \\\n",
       "0                                                                                                      All/O/DT/B-NP/O the/O/DT/I-NP/O home/O/NN/I-NP/O alones/O/VBZ/B-VP/O watching/O/VBG/I-VP/B-EVENT 8/O/CD/B-NP/O mile/O/NN/I-NP/O   \n",
       "1                                                                                                      All/O/DT/B-NP/O the/O/DT/I-NP/O home/O/NN/I-NP/O alones/O/VBZ/B-VP/O watching/O/VBG/I-VP/B-EVENT 8/O/CD/B-NP/O mile/O/NN/I-NP/O   \n",
       "2                                                                                                      All/O/DT/B-NP/O the/O/DT/I-NP/O home/O/NN/I-NP/O alones/O/VBZ/B-VP/O watching/O/VBG/I-VP/B-EVENT 8/O/CD/B-NP/O mile/O/NN/I-NP/O   \n",
       "3  The/O/DT/B-NP/O Ending/O/VBG/I-NP/B-EVENT to/O/TO/I-NP/O 8/O/CD/I-NP/O Mile/O/NNP/I-NP/O is/O/VBZ/B-VP/O my/O/PRP$/B-NP/O fav/O/JJ/I-NP/O part/O/NN/I-NP/O of/O/IN/B-PP/O the/O/DT/B-NP/O whole/O/JJ/I-NP/O movie/O/NN/I-NP/B-EVENT   \n",
       "4  The/O/DT/B-NP/O Ending/O/VBG/I-NP/B-EVENT to/O/TO/I-NP/O 8/O/CD/I-NP/O Mile/O/NNP/I-NP/O is/O/VBZ/B-VP/O my/O/PRP$/B-NP/O fav/O/JJ/I-NP/O part/O/NN/I-NP/O of/O/IN/B-PP/O the/O/DT/B-NP/O whole/O/JJ/I-NP/O movie/O/NN/I-NP/B-EVENT   \n",
       "\n",
       "                                                                                                                                                                                                                                                                   candsenttag  \\\n",
       "0                                                                                                                                                    8/O/NN/B-NP/O mile/O/NN/I-NP/O is/O/VBZ/B-VP/O on/O/IN/B-PP/O thats/O/NNS/B-NP/O my/O/PRP$/B-NP/O movie/O/NN/I-NP/B-EVENT   \n",
       "1                                                                           The/O/DT/B-NP/O last/O/JJ/I-NP/O rap/O/NN/I-NP/B-EVENT battle/O/NN/I-NP/B-EVENT in/O/IN/B-PP/O 8/O/CD/B-NP/O Mile/O/NNP/I-NP/O nevr/O/NN/I-NP/O gets/O/VBZ/B-VP/O old/O/JJ/B-NP/O ahah/O/JJ/I-NP/O   \n",
       "2                                                  The/O/DT/B-NP/O rap/O/NN/I-NP/O battle/O/NN/I-NP/B-EVENT at/O/IN/B-PP/O the/O/DT/B-NP/O end/O/NN/I-NP/O of/O/IN/B-PP/O 8/O/CD/B-NP/O mile/O/NN/I-NP/O gets/O/VBZ/B-VP/O me/O/PRP/B-NP/O so/O/RB/B-ADVP/O hype/O/JJ/I-ADVP/O   \n",
       "3                                                                Rabbit/O/NNP/B-NP/O on/O/IN/B-PP/O 8/O/CD/B-NP/O mile/O/NN/I-NP/O out/O/IN/B-PP/O of/O/IN/B-PP/O place/O/NN/B-NP/O but/O/CC/O/O determined/O/VBD/B-VP/B-EVENT to/O/TO/I-VP/O make/O/VB/I-VP/O it/O/PRP/B-NP/O   \n",
       "4  See/O/VB/B-VP/O 8/O/CD/B-NP/O Mile/O/NNP/I-NP/O is/O/VBZ/B-VP/O always/O/RB/B-ADVP/O on/O/IN/B-PP/O but/O/CC/O/O it/O/PRP/B-NP/O s/O/VBZ/B-VP/O the/O/DT/B-NP/O tv/O/NN/I-NP/O version/O/NN/I-NP/B-EVENT so/O/IN/B-SBAR/O it/O/PRP/B-NP/O s/O/RB/B-ADJP/O gay/O/JJ/I-ADJP/O   \n",
       "\n",
       "  trendid  \n",
       "0      51  \n",
       "1      51  \n",
       "2      51  \n",
       "3      51  \n",
       "4      51  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testfull.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vectors = KeyedVectors.load_word2vec_format(\"word_vectors/numberbatch-en-17.06.txt.gz\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g.:\n",
    "# model.most_similar(positive=['breakfast'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokens(senttag):\n",
    "    return [i.split('/')[0].lower() for i in senttag.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextVect(senttag):\n",
    "    tokens = getTokens(senttag)\n",
    "    vectors = np.array([model_vectors.get_vector(i) for i in tokens\\\n",
    "                        if (i in model_vectors.vocab)\n",
    "                           #&\n",
    "                           #(i not in set(stopwords.words('english')))\\\n",
    "                       ])  \n",
    "    vec = np.sum(vectors, axis=0)/len(vectors)\n",
    "    #vec = np.min(vectors, axis=0)/len(vectors)\n",
    "    if vec.size != 0:\n",
    "        return vec\n",
    "    else:\n",
    "        return np.zeros(300)\n",
    "\n",
    "def givenConcat(row):\n",
    "\n",
    "    return np.append(\\\n",
    "            np.concatenate((row['origDocVec'], row['candDocVec']))\n",
    "            ,\n",
    "            (row['wmdistance'] + row['cosineSim']))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosSim(row):\n",
    "    return cosine_similarity(row['origDocVec'].reshape(1,300), row['candDocVec'].reshape(1,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(trainfull):  \n",
    "    trainfull['origDocVec'] = trainfull['origsenttag'].map(getTextVect)\n",
    "    trainfull['candDocVec'] = trainfull['candsenttag'].map(getTextVect)\n",
    "    trainfull['wmdistance'] = trainfull.apply(lambda row: model_vectors.wmdistance(getTokens(row['origsenttag']),\\\n",
    "                                                               getTokens(row['candsenttag'])),\n",
    "                        axis=1 )\n",
    "    \n",
    "    trainfull['cosineSim'] = trainfull.apply(getCosSim, axis=1)\n",
    "    \n",
    "#     return trainfull\n",
    "    return trainfull[['wmdistance', 'origDocVec', 'candDocVec', 'cosineSim']].apply(givenConcat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = getFeatures(trainfull)\n",
    "y_train = trainfull['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc = LogisticRegression(random_state=42, solver=\"lbfgs\")\n",
    "lrc.fit(list(X_train),  list(y_train.values.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfull['features'] = getFeatures(testfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testfull_1 = testfull[testfull['label'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testfull_1[['features']]\n",
    "y_test = testfull_1['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = lrc.predict(list(X_test['features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.96      0.89       663\n",
      "        True       0.61      0.25      0.35       175\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       838\n",
      "   macro avg       0.72      0.60      0.62       838\n",
      "weighted avg       0.78      0.81      0.78       838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=list(y_test), y_pred=predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_proba = lrc.predict_proba(list(testfull['features']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and output the predictions\n",
    "def OutputPredictions(predicted_proba, outfile):\n",
    "           \n",
    "    # output the results into a file\n",
    "    outf = open(outfile,'w') \n",
    "          \n",
    "    for prob in predicted_proba:\n",
    "        if prob[0] >= 0.5:\n",
    "             outf.write(\"true\\t\" + \"{0:.4f}\".format(prob[0]) + \"\\n\")\n",
    "        else:\n",
    "             outf.write(\"false\\t\" + \"{0:.4f}\".format(prob[0]) + \"\\n\")\n",
    "             \n",
    "    outf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfilename = \"./systemoutputs/PIT2015_BASELINE_MY_LG.output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutputPredictions(predicted_proba, outputfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838\tBASELINE\tMY_LG\t\tF: 0.280\tPrec: 0.172\tRec: 0.754\t\tP-corr: -0.381\tF1: 0.346\tPrec: 0.209\tRec: 1.000\r\n"
     ]
    }
   ],
   "source": [
    "!python scripts/pit2015_eval_single.py ./data/test.label ./systemoutputs/PIT2015_BASELINE_MY_LG.output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "фічі\n",
    "- вектор документу 1\n",
    "- вектор документу 2\n",
    "- Word Mover’s Distance between two documents\n",
    "- cosine similarity"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- забираючи стоп слова F1 залишилось тим же, але Precision та Recall знизились, тому стоп слова не забирала\n",
    "- створюючи вектор документу як агрегуючу функцію пробувала sum/max/min, sum виявилась за показниками найкраща\n",
    "- додавши cosine_similarity фічу recall підвищився з тим самим F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
